import subprocessimport requestsimport timeimport signalimport jsonimport platformimport osimport threadingimport randomfrom statistics import meanfrom datetime import datetimeimport builtins as _biNAMESPACE = "gobgp-lab"TARGET_PORT = 8080LOCAL_BASE_PORT = 18080RUNS = 3OBSERVE_INTERVAL = float(os.getenv("OBSERVE_INTERVAL_S", "1.0"))CONNECT_TIMEOUT = float(os.getenv("CONNECT_TIMEOUT_S", "0.8"))READ_TIMEOUT = float(os.getenv("READ_TIMEOUT_S", "0.8"))PORTFWD_READY_RETRIES = int(os.getenv("PORTFWD_READY_RETRIES", "40"))PORTFWD_READY_SLEEP = float(os.getenv("PORTFWD_READY_SLEEP_S", "0.25"))LONG_OP_TIMEOUTS = {    "/noise/start": float(os.getenv("NOISE_START_TIMEOUT_S", "30")),    "/noise/stop":  float(os.getenv("NOISE_STOP_TIMEOUT_S",  "180")),    "/pcap/start":  float(os.getenv("PCAP_START_TIMEOUT_S",  "20")),    "/pcap/stop":   float(os.getenv("PCAP_STOP_TIMEOUT_S",   "120")),}EU_TIME_FMT = "%d.%m.%Y %H:%M:%S"__orig_print = _bi.printdef print(*args, **kwargs):    __orig_print(f"[{datetime.now().strftime(EU_TIME_FMT)}]", *args, **kwargs)STABLE_SAMPLES = int(os.getenv("STABLE_SAMPLES", "3"))TIMESTAMP = datetime.now().strftime("%Y%m%d-%H%M%S")BASE_EXPERIMENT_DIR = os.path.join("experiments", TIMESTAMP)os.makedirs(BASE_EXPERIMENT_DIR, exist_ok=True)SEQUENCE = [    {"gate": "start_watchers"},    {"pod": "aachen", "method": "POST", "path": "/noise/start",     "json": {"PREFIX_BLOCK": 0, "NUMBER_OF_BLOCKS": 1, "rate": 1.0,              "lifetime": 60, "jitter": 0.5, "max_active": 60}},    {"wait": 30},    {"pod": "aachen", "method": "POST", "path": "/noise/pause"},    {"wait": 30},    {"pod": "aachen", "method": "POST", "path": "/noise/drain", "json": {"percent": 50}},    {"wait": 30},    {"pod": "aachen", "method": "POST", "path": "/noise/stop"},    {"gate": "wait_for_drain"},]GATES = {}def gate(name):    def wrapper(fn):        GATES[name] = fn        return fn    return wrapperdef get_running_pods():    cmd = ["kubectl", "get", "pods", "-n", NAMESPACE, "-o", "json"]    out = subprocess.check_output(cmd, text=True)    data = json.loads(out)    return [item["metadata"]["name"]            for item in data["items"]            if item["status"]["phase"] == "Running"]def resolve_pod_name(name_or_prefix: str) -> str:    if "-" in name_or_prefix:        return name_or_prefix    for name in get_running_pods():        if name.startswith(name_or_prefix):            return name    raise RuntimeError(f"No running pod found with prefix '{name_or_prefix}'")def port_forward(pod: str, local_port: int):    cmd = ["kubectl", "port-forward", f"pod/{pod}", f"{local_port}:{TARGET_PORT}", "-n", NAMESPACE]    return subprocess.Popen(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)def stop_process(proc):    if not proc:        return    if platform.system() == "Windows":        proc.terminate()    else:        proc.send_signal(signal.SIGINT)    try:        proc.wait(timeout=3)    except subprocess.TimeoutExpired:        proc.kill()def request_json(base_url, method, path, *, read_timeout=None, **kwargs):    rt = read_timeout if read_timeout is not None else READ_TIMEOUT    timeout = kwargs.pop("timeout", (CONNECT_TIMEOUT, rt))    func = getattr(requests, method.lower())    try:        r = func(base_url + path, timeout=timeout, **kwargs)    except requests.RequestException as e:        return 599, {"error": str(e)}    try:        return r.status_code, r.json()    except Exception:        return r.status_code, r.textdef wait_port_forward_ready(base_url):    for _ in range(PORTFWD_READY_RETRIES):        status, _ = request_json(base_url, "GET", "/ip", read_timeout=2.0)        if status == 200:            return True        time.sleep(PORTFWD_READY_SLEEP)    return Falsedef wait_for_pods_ready():    while True:        pods = get_running_pods()        if pods:            return        time.sleep(2)def reset_environment():    print("[Setup] uninstalling previous release...")    subprocess.run(["helm", "uninstall", "gobgp-lab", "-n", NAMESPACE], check=False)    print("[Setup] installing fresh release...")    subprocess.run([        "helm", "upgrade", "--install",        "gobgp-lab", "gobgp-lab",        "-n", NAMESPACE, "--create-namespace"    ], check=True)    wait_for_pods_ready()    print("[Setup] waiting 30s for stabilization...")    time.sleep(30)def rib_observer(pod_name, base_url, results_dict, stop_event):    print(f"[Watcher] starting for {pod_name}")    series = []    start_ts = time.time()    stable_count = 0    saw_nonzero = False    drained = False    first_drained_ts = None    results_dict[pod_name] = {"series": [], "drained": False, "saw_nonzero": False,                              "time_to_zero": None, "last_sample_ts": None, "reason": "watching"}    time.sleep(random.uniform(0, OBSERVE_INTERVAL))    while not stop_event.is_set():        status_sum, rib_sum = request_json(base_url, "GET", "/rib/summary", read_timeout=max(READ_TIMEOUT, 2.0))        status_len, rib_len = request_json(base_url, "GET", "/rib/pathlengths", read_timeout=max(READ_TIMEOUT, 2.0))        now = time.time()        if status_sum == 200 and isinstance(rib_sum, dict):            num_paths = int(rib_sum.get("num_paths", 0))            min_len = rib_len.get("min", 0) if status_len == 200 and isinstance(rib_len, dict) else None            avg_len = rib_len.get("avg", 0.0) if status_len == 200 and isinstance(rib_len, dict) else None            max_len = rib_len.get("max", 0) if status_len == 200 and isinstance(rib_len, dict) else None            series.append({"ts": now, "ts_local": datetime.fromtimestamp(now).strftime(EU_TIME_FMT),                           "num_paths": num_paths, "path_len_min": min_len,                           "path_len_avg": avg_len, "path_len_max": max_len})            if num_paths > 0:                saw_nonzero = True; stable_count = 0; drained = False            else:                if saw_nonzero:                    stable_count += 1                    if not drained and stable_count >= STABLE_SAMPLES:                        drained = True; first_drained_ts = first_drained_ts or now            results_dict[pod_name] = {"series": series, "drained": drained, "saw_nonzero": saw_nonzero,                                      "time_to_zero": (first_drained_ts - start_ts) if first_drained_ts else None,                                      "last_sample_ts": now, "reason": "watching"}        time.sleep(OBSERVE_INTERVAL)    results_dict[pod_name] = {"series": series, "drained": drained, "saw_nonzero": saw_nonzero,                              "time_to_zero": (first_drained_ts - start_ts) if first_drained_ts else None,                              "last_sample_ts": time.time(), "reason": "stopped_by_gate"}    print(f"[Watcher] finished for {pod_name} drained={drained}")def connect_if_needed(pod_connections, name_or_prefix):    pod_name = resolve_pod_name(name_or_prefix)    key = pod_name    if key not in pod_connections:        local_port = LOCAL_BASE_PORT + len(pod_connections)        print(f"[Main] port-forward {pod_name} on {local_port}")        proc = port_forward(pod_name, local_port)        base = f"http://localhost:{local_port}"        if not wait_port_forward_ready(base):            stop_process(proc)            raise RuntimeError(f"port-forward not ready for {pod_name} on {local_port}")        pod_connections[key] = (proc, pod_name, local_port)    return pod_connections[key]@gate("start_watchers")def start_watchers_gate(_base_url, step, results, state):    print("[Gate] start_watchers")    pods = get_running_pods()    watch = {"threads": [], "stop_event": threading.Event(), "results": {}, "watched_pods": []}    state["watch"] = watch    for full_name in pods:        if full_name.startswith("aachen"):            continue        proc, pod_name, local_port = connect_if_needed(state["pod_connections"], full_name)        base = f"http://localhost:{local_port}"        t = threading.Thread(target=rib_observer, args=(pod_name, base, watch["results"], watch["stop_event"]), daemon=True)        t.start()        watch["threads"].append(t)        watch["watched_pods"].append(pod_name)    return {"gate": "start_watchers", "watching": state["watch"]["watched_pods"]}@gate("wait_for_drain")def wait_for_drain_gate(_base_url, step, results, state):    print("[Gate] wait_for_drain")    all_stable_rounds = max(1, STABLE_SAMPLES)    stable_count = 0    while True:        statuses = [bool(state["watch"]["results"].get(p, {}).get("drained")) for p in state["watch"]["watched_pods"]]        if all(statuses):            stable_count += 1        else:            stable_count = 0        if stable_count >= all_stable_rounds:            print("[Gate] all watchers drained")            break        time.sleep(OBSERVE_INTERVAL)    state["watch"]["stop_event"].set()    for t in state["watch"]["threads"]:        t.join(timeout=max(5.0, 5 * OBSERVE_INTERVAL))    return {"gate": "wait_for_drain", "drained": True, "stable_rounds": all_stable_rounds}def run_step(base_url, step, pod_name, exp_dir):    url = base_url + step["path"]    method = step["method"].lower()    kwargs = {}    if "json" in step:        kwargs["json"] = step["json"]    read_timeout = max(LONG_OP_TIMEOUTS.get(step["path"], READ_TIMEOUT), READ_TIMEOUT)    print(f"[Main] {pod_name} {step['method']} {step['path']} (rt={read_timeout}s)")    action_entry = {"pod": pod_name, "method": step["method"].upper(), "path": step["path"]}    try:        resp = requests.request(method, url, timeout=(CONNECT_TIMEOUT, read_timeout), **kwargs)        try:            parsed = resp.json()        except Exception:            parsed = resp.text        action_entry["result"] = {"status": resp.status_code, "response": parsed}    except requests.RequestException as e:        action_entry["result"] = {"status": "ERROR", "response": str(e)}        return {"action": action_entry}    return {"action": action_entry}def run_experiment(run_id):    reset_environment()    exp_dir = os.path.join(BASE_EXPERIMENT_DIR, str(run_id))    os.makedirs(exp_dir, exist_ok=True)    results = []    pod_connections = {}    state = {"pod_connections": pod_connections}    try:        for step in SEQUENCE:            if "wait" in step:                time.sleep(step["wait"]); results.append({"wait": step["wait"]}); continue            if "gate" in step:                fn = GATES.get(step["gate"])                gate_result = fn(None, step, results, state) if fn else {"gate": step["gate"], "error": "unknown gate"}                results.append(gate_result); continue            proc, pod_name, local_port = connect_if_needed(pod_connections, step["pod"])            base_url = f"http://localhost:{local_port}"            results.append(run_step(base_url, step, pod_name, exp_dir))    finally:        if "watch" in state: state["observers"] = state["watch"]["results"]        for proc, _, _ in pod_connections.values(): stop_process(proc)    report = {"generated": datetime.now().isoformat(), "namespace": NAMESPACE,              "experiment_dir": exp_dir, "sequence": results, "observers": state.get("observers", {}),              "drain_parameters": {"stable_samples": STABLE_SAMPLES}}    with open(os.path.join(exp_dir, "report.json"), "w") as f: json.dump(report, f, indent=2)    return reportdef main():    reports = []    for i in range(1, RUNS + 1):        print(f"[Main] Starting run {i}/{RUNS}")        reports.append(run_experiment(i))    times = [obs[p]["time_to_zero"] for rep in reports for p, obs in rep.get("observers", {}).items() if obs.get("time_to_zero")]    summary = {"runs": RUNS, "time_to_zero": {"min": min(times) if times else None,                                              "max": max(times) if times else None,                                              "avg": mean(times) if times else None}}    with open(os.path.join(BASE_EXPERIMENT_DIR, "summary.json"), "w") as f: json.dump(summary, f, indent=2)    print(f"[Main] Summary saved under {BASE_EXPERIMENT_DIR}")if __name__ == "__main__":    main()